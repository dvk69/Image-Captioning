# Image-Captioning
Image captioning is a job that combines computer vision and natural language processing. The features of NLP (Natural Language Processing) models are used in the research study. Models are typically evaluated according to a BLEU or CIDER metric, with the goal of generating meaningful legends for pictures.

Image caption generation is based on CNN and RNN functionality. The development was done in Jupyter Notebook and the Keras Library was used. The Python programming language was used to implement this work.
This challenge was hypothetical even to the most advanced researchers in Computer Vision before the recent emergence of Deep Neural Networks. However, with the introduction of Deep Learning, this challenge may be readily handled provided the necessary dataset is available.
In addition to CNN, Natural Language Processing is employed to create image captions. LSTMs are specialized Recurrent Neural Networks that allow data to be retained. For picture classification, the VGG16 model has been used, which has been pre-trained on the ImageNet dataset.

Now download the dataset from your local computer and upload it into your google drive.
Find the code and load it into Google Colab. 
Run it to see the results.
